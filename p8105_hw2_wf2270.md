P8105 HW2
================
Wenbo Fei
9/29/2020

# Problem 1

Read the Mr.Trashwheel dataset

``` r
trashwheel_df = 
  read_xlsx("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
            sheet = "Mr. Trash Wheel",
            range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )

head(trashwheel_df)
```

    ## # A tibble: 6 x 14
    ##   dumpster month  year date                weight_tons volume_cubic_ya…
    ##      <dbl> <chr> <dbl> <dttm>                    <dbl>            <dbl>
    ## 1        1 May    2014 2014-05-16 00:00:00        4.31               18
    ## 2        2 May    2014 2014-05-16 00:00:00        2.74               13
    ## 3        3 May    2014 2014-05-16 00:00:00        3.45               15
    ## 4        4 May    2014 2014-05-17 00:00:00        3.1                15
    ## 5        5 May    2014 2014-05-17 00:00:00        4.06               18
    ## 6        6 May    2014 2014-05-20 00:00:00        2.71               13
    ## # … with 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, grocery_bags <dbl>,
    ## #   chip_bags <dbl>, sports_balls <int>, homes_powered <dbl>

Read the precipitation data from 2018 and 2017

``` r
precip_2018 = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)

precip_2017 = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)
```

Now combine annual precipitation

``` r
precip_df = 
  bind_rows(precip_2018, precip_2017)

month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )
  
precip_df = left_join(precip_df, month_df, by = "month")
head(precip_df)
```

    ## # A tibble: 6 x 4
    ##    year month total month_name
    ##   <dbl> <dbl> <dbl> <chr>     
    ## 1  2018     1  0.94 January   
    ## 2  2018     2  4.8  February  
    ## 3  2018     3  2.69 March     
    ## 4  2018     4  4.69 April     
    ## 5  2018     5  9.27 May       
    ## 6  2018     6  4.77 June

The first dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collector collects the trash and store it in a dumpster. This
dataset contained detailed information on year, month and trash
collected, including some specific kinds of trash. There are a total of
344 observations in our final dataset. Each observation has a unique
“dumpster” number, while the corresponding year, date, weight of
trash(in tons), volume of trash(in cubic yards) and the number some
specific kinds of trash will be recorded.

The second dataset includes month precipitation data from year 2018 and
2017. There are a total of 24 observations in our final dataset. Each
observation includes the total precipitation corresponding to specific
month and year.

The total precipitation in 2018 is 70.33. The median number of sports
balls in a dumpster in 2017 is 8

# Problem 2

Read and clean the data; retain line, station, name, station latitude /
longitude, routes served, entry, vending, entrance type, and ADA
compliance. Convert the entry variable from character (YES vs NO) to a
logical variable.

``` r
NYC_transit = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(c(line:route11, entry, vending, entrance_type, ada)) %>%
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE),
         vending = recode(vending, "YES" = TRUE, "NO" = FALSE)) %>%
  mutate_at(vars(route1:route11), as.character) %>%
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    names_prefix = "route",
    values_to = "route_number" ) %>%
  drop_na(route_number)
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

Write a short paragraph about this dataset – explain briefly what
variables the dataset contains, describe your data cleaning steps so
far, and give the dimension (rows x columns) of the resulting dataset.
Are these data tidy?

This NYC\_transit dataset contains information related to each entrance
and exit for each subway station in NYC, it has 4270 observations and 10
variables in my dataset after cleaning. For each observations, there are
variables describing line, station name, station latitude, station
longitude, whether it’s an entry, whether it has vending machine, the
entrance type, whether it’s ADA compliant, and the route name and route
number.

After reading in the data, I first clean the variables names, select my
interested variables, convert the entry and vending columns into logical
values. Then since the route data is spread across 11 columns, I use
pivot\_longer to convert route1:route11 into a route name column, with
their corresponding value stored in route number column. To retain the
route served, I drop those observation with route number=NA. The
dimension of the resulting dataset is 4270 x 10 , I think they are tidy
now.
