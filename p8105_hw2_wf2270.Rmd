---
title: "P8105 HW2"
author: "Wenbo Fei"
date: "9/29/2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
```

# Problem 1

Read the Mr.Trashwheel dataset
```{r P1_readdata1}
trashwheel_df = 
  read_xlsx("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
            sheet = "Mr. Trash Wheel",
            range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )

head(trashwheel_df)
```

Read the precipitation data from 2018 and 2017
```{r P1_readdata2}
precip_2018 = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)

precip_2017 = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)
```

Now combine annual precipitation
```{r P1binddata}
precip_df = 
  bind_rows(precip_2018, precip_2017)

month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )
  
precip_df = left_join(precip_df, month_df, by = "month")
head(precip_df)
```

The first dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collector collects the trash and store it in a dumpster. This dataset contained detailed information on year, month and trash collected, including some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` observations in our final dataset. Each observation has a unique "dumpster" number, while the corresponding year, date, weight of trash(in tons), volume of trash(in cubic yards) and the number some specific kinds of trash will be recorded.

The second dataset includes month precipitation data from year 2018 and 2017. There are a total of `r nrow(precip_df)` observations in our final dataset. Each observation includes the total precipitation corresponding to specific month and year.  

The total precipitation in 2018 is `r sum(pull(precip_2018, total))`. The median number of sports balls in a dumpster in 2017 is `r median(pull(subset(trashwheel_df, year = 2017), sports_balls))`. 

# Problem 2

```{r P2, message=FALSE}
NYC_transit = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(c(line:route11, entry, vending, entrance_type, ada)) %>%
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE),
         vending = recode(vending, "YES" = TRUE, "NO" = FALSE)) %>%
  mutate_at(vars(route1:route11), as.character) %>%
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    names_prefix = "route",
    values_to = "route_number" ) %>%
  drop_na(route_number)

head(NYC_transit)
```


This NYC_transit dataset contains information related to each entrance and exit for each subway station in NYC, it has `r nrow(NYC_transit)` observations and `r ncol(NYC_transit)` variables in my dataset after cleaning. For each observations, there are variables describing line, station name, station latitude, station longitude, whether it's an entry, whether it has vending machine, the entrance type, whether it's ADA compliant, and the route name and route number.

After reading in the data, I first clean the variables names, select my interested variables, convert the entry and vending columns into logical values. Then since the route data is spread across 11 columns, I use pivot_longer to reformat route1:route11 into a route name column, with their corresponding value stored in route number column. To retain the route served, I drop those observation with route number=NA. The dimension of the resulting dataset is `r nrow(NYC_transit)` x `r ncol(NYC_transit)` , I think they are tidy now.

Answer questions:

* There are `r nrow(distinct(NYC_transit, line, station_name))` distinct stations.

* There are `r nrow(distinct(filter(NYC_transit, ada == TRUE), line, station_name))` stations are ADA compliant.

* The proportion of station entrances / exits without vending allow entrance is `r nrow(filter(NYC_transit, vending == FALSE & entry == TRUE))/nrow(filter(NYC_transit, vending == FALSE))`.


Route number and route name have been reformated in the data cleaning process above. There are `r nrow(distinct(filter(NYC_transit, route_number == "A"), line, station_name))` distinct stations serve the A train. Of the stations that serve the A train, `r nrow(distinct(filter(NYC_transit, route_number == "A" & ada == TRUE), line, station_name))` are ADA compliant.

# Problem 3

First, clean the data in pols-month.csv. Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.

```{r P3read1, message=FALSE}
pols_df = 
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day"), sep = "-") %>%
  mutate_at(vars(year:day), as.integer) %>%
  mutate(
    month = month.name[month], # change month number to name
    president = ifelse(prez_gop == 0,"dem","gop")) %>% #create president variable
  subset(select = -c(prez_dem, prez_gop, day))

head(pols_df)
```

Second, clean the data in snp.csv using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.


```{r P3read2, message=FALSE}
snp_df = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year"), sep = "/") %>%
  mutate_at(vars(month:year), as.integer) %>%
  arrange(year, month) %>%#arrange according to year and month
  mutate(month = month.name[month]) %>% # change month number to name
  subset(select = -day) %>%
  relocate(year, month)

head(snp_df)
```

Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

```{r P3read3, message=FALSE}
month_df2 = tibble(
    mon = month.abb,
    month = month.name,
    month_number = 1:12
  )

unemployment_df = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
  pivot_longer(
    Jan:Dec,
    names_to = "mon",
    values_to = "unemployment" ) %>%
  drop_na(unemployment) %>%
  left_join(month_df2, by = "mon") %>%
  janitor::clean_names() %>%
  mutate_at("year", as.integer) %>%
  arrange(year, month_number) %>% # arrange according to year and month
  subset(select = -c(mon, month_number)) %>%
  relocate(year, month)

head(unemployment_df)
```

Join the datasets.
```{r P3merge}
final_df = 
  full_join(pols_df, snp_df, c("year", "month")) %>%
  full_join(unemployment_df, c("year", "month"))
head(final_df)
```

The pols_df dataset contains `r nrow(pols_df)` observations of `r ncol(pols_df)` variables related to the number of national politicians who are democratic(gov_dem, sen_dem, rep_dem) or republican(gov_gop, sen_gop, rep_gop), and whether the president are democratic or republican(president) at any given month(month) in a given year(year) from Jan, 1947 - Jun, 2015. 

The snp_df dataset contains `r nrow(snp_df)` observations of `r ncol(snp_df)` variables related to the closing values of the S&P stock index(close) at a given month(month) in a given year(year) from Jan, 1950 - Jul, 2015.

The unemployment_df dataset contains `r nrow(unemployment_df)` observations of `r ncol(unemployment_df)` variables related to the percentage of unemployment(unemployment) at a given month(month) in a given year(year) from Jan, 1948 - Jun, 2015.

The final_df is merged from the previous 3 datasets using year and month as keys across datasets. It contains `r nrow(final_df)` observations of `r ncol(final_df)` variables.

